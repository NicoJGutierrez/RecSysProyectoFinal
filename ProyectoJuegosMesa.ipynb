{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH8fyVEjke2x"
   },
   "source": [
    "# Propuesta Proyecto RecSys: Recomendación Grupal de Juegos de Mesa (setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygicq0KDTnqq"
   },
   "source": [
    "Link de dataset: https://www.kaggle.com/datasets/threnjen/board-games-database-from-boardgamegeek?select=games.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMyiOuV3TyEZ",
    "outputId": "47f7b763-4a2e-4870-c41c-19086124f114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyreclab in /home/nico/.local/lib/python3.10/site-packages (0.1.16)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: implicit in /home/nico/.local/lib/python3.10/site-packages (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/nico/.local/lib/python3.10/site-packages (from implicit) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl in /home/nico/.local/lib/python3.10/site-packages (from implicit) (3.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nico/.local/lib/python3.10/site-packages (from implicit) (4.66.5)\n",
      "Requirement already satisfied: scipy>=0.16 in /home/nico/.local/lib/python3.10/site-packages (from implicit) (1.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: surprise in /home/nico/.local/lib/python3.10/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /home/nico/.local/lib/python3.10/site-packages (from surprise) (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/nico/.local/lib/python3.10/site-packages (from scikit-surprise->surprise) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/nico/.local/lib/python3.10/site-packages (from scikit-surprise->surprise) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/nico/.local/lib/python3.10/site-packages (from scikit-surprise->surprise) (1.4.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement elliot (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for elliot\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Requirement already satisfied: jinja2 in /home/nico/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Requirement already satisfied: fsspec in /home/nico/.local/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Collecting triton==3.1.0\n",
      "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/nico/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: networkx in /home/nico/.local/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: filelock in /home/nico/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/nico/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nico/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/nico/.local/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: numpy in /home/nico/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nico/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.68\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.68:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.68\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle\n",
    "!pip install pyreclab\n",
    "!pip install implicit\n",
    "!pip install surprise\n",
    "!pip install elliot\n",
    "!pip install torch torchvision\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzALElwIUwwS"
   },
   "source": [
    "Tutorial usado: https://www.kaggle.com/discussions/general/74235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu7OpwbIW4Hu"
   },
   "source": [
    "Tutorial adicional usado: https://www.youtube.com/watch?v=yEXkEUqK52Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/threnjen/board-games-database-from-boardgamegeek?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148M/148M [00:56<00:00, 2.72MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/nico/.cache/kagglehub/datasets/threnjen/board-games-database-from-boardgamegeek/versions/4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"threnjen/board-games-database-from-boardgamegeek\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arriba de esto aparecerá un \"path to dataset files\", ese path se debe copiar y pegar en la línea de abajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_Y1R8PyNW2pp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset_files = '/home/nico/.cache/kagglehub/datasets/threnjen/board-games-database-from-boardgamegeek/versions/4'\n",
    "import os\n",
    "# Guardamos el directorio actual\n",
    "base_dir = os.getcwd()\n",
    "# Cambiamos al directorio donde se encuentra el dataset\n",
    "os.chdir(path_to_dataset_files)\n",
    "\n",
    "# Importamos las librerias\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreclab\n",
    "import tempfile\n",
    "import implicit\n",
    "import random\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZBjZKWDK2Uq"
   },
   "source": [
    "Generamos los datos a utilizar como un muestreo del dataset original pues es muy grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UX_VaAH9Xs-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nico/sysrec/RecSysProyectoFinal\n"
     ]
    }
   ],
   "source": [
    "# Leemos el csv y volvemos al directorio base del proyecto\n",
    "user_ratings = pd.read_csv('user_ratings.csv')\n",
    "mechanics_df = pd.read_csv('mechanics.csv')\n",
    "# Volvemos al directorio base del proyecto\n",
    "os.chdir(base_dir)\n",
    "print(base_dir)\n",
    "\n",
    "# Cambiamos username por un userid\n",
    "a=list(set(list(user_ratings.Username)))\n",
    "d = {a[i]: i for i in range(len(a))}\n",
    "a_mod = [d[i] for i in list(user_ratings.Username)]\n",
    "user_ratings[\"Username\"] = a_mod\n",
    "\n",
    "# Separamos training y testing\n",
    "train     = list(set(user_ratings.Username))[:8000]\n",
    "test      = list(set(user_ratings.Username))[8000:11000]\n",
    "test_set  = user_ratings[user_ratings[\"Username\"].isin(test)].sample(9000)\n",
    "train_set = user_ratings[user_ratings[\"Username\"].isin(train)].sample(35000)\n",
    "\n",
    "# Generamos nuevo csv de training y testing\n",
    "train_set.to_csv(\"train.csv\", index=False, sep=',', header=True)\n",
    "test_set.to_csv(\"test.csv\", index=False, sep=',', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhdLEKTqLXKj"
   },
   "source": [
    "# Evaluación de baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0g_ntaRqxwgK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BGGId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14775124</th>\n",
       "      <td>241831</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546321</th>\n",
       "      <td>173346</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675919</th>\n",
       "      <td>125618</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995743</th>\n",
       "      <td>463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950019</th>\n",
       "      <td>19348</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485562</th>\n",
       "      <td>195232</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705616</th>\n",
       "      <td>822</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727001</th>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9941629</th>\n",
       "      <td>206718</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14947710</th>\n",
       "      <td>69120</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BGGId  Rating  Username\n",
       "14775124  241831     8.0      9405\n",
       "1546321   173346     8.0      8375\n",
       "8675919   125618     8.0      9966\n",
       "1995743      463     5.0     10101\n",
       "15950019   19348     7.0      8261\n",
       "485562    195232     7.0     10734\n",
       "1705616      822     8.0      9831\n",
       "1727001       50     5.0     10201\n",
       "9941629   206718     8.0      8461\n",
       "14947710   69120     7.0      8061"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trabajaremos con un top 10\n",
    "top_n = 10\n",
    "test_set.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset completo: (18942215, 3)\n",
      "Tamaño del dataset de entrenamiento: (35000, 3)\n",
      "Tamaño del dataset de prueba: (9000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Revisemos el tamaño del dataset para asegurarnos de que tiene un tamaño trabajable:\n",
    "print(\"Tamaño del dataset completo:\", user_ratings.shape)\n",
    "print(\"Tamaño del dataset de entrenamiento:\", train_set.shape)\n",
    "print(\"Tamaño del dataset de prueba:\", test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rF526_4zGS7",
    "outputId": "26a3ea2f-6e4f-4257-85d3-b9357f31eaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: <user: 4263 ,item: 42> pair duplicated on line 9622\n",
      "warning: <user: 2019 ,item: 175> pair duplicated on line 20510\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "SIGINT received",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluamos UserKNN\u001b[39;00m\n\u001b[1;32m      2\u001b[0m myUserKnn \u001b[38;5;241m=\u001b[39m pyreclab\u001b[38;5;241m.\u001b[39mUserKnn(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmyUserKnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpearson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m _, maeUK, rmseUK \u001b[38;5;241m=\u001b[39m myUserKnn\u001b[38;5;241m.\u001b[39mtest(input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dlmchar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, usercol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, itemcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, ratingcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m _, mapUK, ndcgUK \u001b[38;5;241m=\u001b[39m myUserKnn\u001b[38;5;241m.\u001b[39mtestrec(input_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, topn\u001b[38;5;241m=\u001b[39mtop_n)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: SIGINT received"
     ]
    }
   ],
   "source": [
    "# Evaluamos UserKNN\n",
    "myUserKnn = pyreclab.UserKnn(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myUserKnn.train(k=7, similarity='pearson')\n",
    "_, maeUK, rmseUK = myUserKnn.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapUK, ndcgUK = myUserKnn.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeUK} y rmse = {rmseUK}\")\n",
    "print(f\"map = {mapUK} y ndcg = {ndcgUK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUPkB3E4v1fo",
    "outputId": "69b494c9-67d0-4110-f8f1-2bca5084cbcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: <user: 4263 ,item: 42> pair duplicated on line 9622\n",
      "warning: <user: 2019 ,item: 175> pair duplicated on line 20510\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "SIGINT received",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluamos ItemKNN\u001b[39;00m\n\u001b[1;32m      2\u001b[0m myItemKnn \u001b[38;5;241m=\u001b[39m pyreclab\u001b[38;5;241m.\u001b[39mItemKnn(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmyItemKnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpearson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m _, maeIK, rmseIK \u001b[38;5;241m=\u001b[39m myItemKnn\u001b[38;5;241m.\u001b[39mtest(input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dlmchar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, usercol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, itemcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, ratingcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m _, mapIK, ndcgIK \u001b[38;5;241m=\u001b[39m myItemKnn\u001b[38;5;241m.\u001b[39mtestrec(input_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, topn\u001b[38;5;241m=\u001b[39mtop_n)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: SIGINT received"
     ]
    }
   ],
   "source": [
    "# Evaluamos ItemKNN\n",
    "myItemKnn = pyreclab.ItemKnn(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myItemKnn.train(k=7, similarity='pearson')\n",
    "_, maeIK, rmseIK = myItemKnn.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapIK, ndcgIK = myItemKnn.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeIK} y rmse = {rmseIK}\")\n",
    "print(f\"map = {mapIK} y ndcg = {ndcgIK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7L7aVu-qzRY_",
    "outputId": "023604bd-526e-44ef-e63a-533c21ae19e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Constructor signature used is deprecated. From now on, it should include 'factors' parameter. See documentation for more information.\n",
      "warning: <user: 4263 ,item: 42> pair duplicated on line 9622\n",
      "warning: <user: 2019 ,item: 175> pair duplicated on line 20510\n",
      "Warning: Train signature used is deprecated. From now on, 'factors' parameter should be provided in model's constructor. See documentation for more information.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "SIGINT received",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluamos SVD\u001b[39;00m\n\u001b[1;32m      2\u001b[0m mySVD \u001b[38;5;241m=\u001b[39m pyreclab\u001b[38;5;241m.\u001b[39mSVD(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmySVD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m _, maeSVD, rmseSVD \u001b[38;5;241m=\u001b[39m mySVD\u001b[38;5;241m.\u001b[39mtest(input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dlmchar \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, usercol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, itemcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, ratingcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m _, mapSVD, ndcgSVD \u001b[38;5;241m=\u001b[39m mySVD\u001b[38;5;241m.\u001b[39mtestrec(input_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, topn\u001b[38;5;241m=\u001b[39mtop_n)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: SIGINT received"
     ]
    }
   ],
   "source": [
    "# Evaluamos SVD\n",
    "mySVD = pyreclab.SVD(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "mySVD.train(factors=50, maxiter=80, lr=0.1, lamb=0.5)\n",
    "_, maeSVD, rmseSVD = mySVD.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapSVD, ndcgSVD = mySVD.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeSVD} y rmse = {rmseSVD}\")\n",
    "print(f\"map = {mapSVD} y ndcg = {ndcgSVD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efI8FJ00VMF2",
    "outputId": "0bebd840-5764-47ec-a765-ce0d53de9320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: <user: 4263 ,item: 42> pair duplicated on line 9622\n",
      "warning: <user: 2019 ,item: 175> pair duplicated on line 20510\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "SIGINT received",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluamos Most Popular\u001b[39;00m\n\u001b[1;32m      2\u001b[0m myMP \u001b[38;5;241m=\u001b[39m pyreclab\u001b[38;5;241m.\u001b[39mMostPopular(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmyMP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m _, mapMP, ndcgMP \u001b[38;5;241m=\u001b[39m myMP\u001b[38;5;241m.\u001b[39mtestrec(input_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, dlmchar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, usercol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, itemcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ratingcol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, topn\u001b[38;5;241m=\u001b[39mtop_n)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapMP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m y ndcg = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndcgMP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: SIGINT received"
     ]
    }
   ],
   "source": [
    "# Evaluamos Most Popular\n",
    "myMP = pyreclab.MostPopular(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myMP.train(progress=False)\n",
    "_, mapMP, ndcgMP = myMP.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"map = {mapMP} y ndcg = {ndcgMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofL_ECIkRH-r",
    "outputId": "2a24baa8-e89d-4f97-8fef-bd99c59f2e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.4717\n",
      "MAE:  2.8420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.841987734361642"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluamos Random ratings\n",
    "predictions = []\n",
    "\n",
    "rating_scale = (1, 10)\n",
    "\n",
    "for _, row in test_set.iterrows():\n",
    "    itemId = row[\"BGGId\"]; rating = row[\"Rating\"]; userId = row[\"Username\"]\n",
    "    random_rating = random.uniform(rating_scale[0], rating_scale[1])\n",
    "    predictions.append((userId, itemId, rating, random_rating, None))\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = train_set\n",
    "cols_with_id = {col: idx for idx, col in enumerate(mechanics_df.columns[1:])}\n",
    "\n",
    "# Conjunto de features\n",
    "item_styles = {}\n",
    "\n",
    "for _, row in train_set.iterrows():\n",
    "    bgg_id = row['BGGId']\n",
    "    style_row = mechanics_df[mechanics_df['BGGId'] == bgg_id].drop(columns=['BGGId'])\n",
    "    styles = style_row.columns[style_row.iloc[0] == 1].tolist()\n",
    "    item_styles[bgg_id] = styles\n",
    "\n",
    "print(item_styles)\n",
    "\n",
    "\n",
    "\n",
    "itemslist = df['BGGId'].unique()\n",
    "userslist = df['Username'].unique()\n",
    "stylelist = [i for i in range(len(cols_with_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjunto de features, pero numericos\n",
    "\n",
    "item_styles_with_ids = {}\n",
    "for item_id, styles in item_styles.items():\n",
    "    style_ids = [cols_with_id[style] for style in styles]\n",
    "    item_styles_with_ids[item_id] = style_ids\n",
    "print(item_styles_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [(row['Username'], row['BGGId'], row['Rating']) for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "all_features = set(feature for features in item_styles.values() for feature in features)\n",
    "\n",
    "dataset.fit(users=userslist, items=itemslist, item_features=all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions_matrix, weights_matrix) = dataset.build_interactions(\n",
    "    ((x[0], x[1], x[2]) for x in interactions)\n",
    ")\n",
    "\n",
    "item_features = dataset.build_item_features(\n",
    "    ((item_id, features) for item_id, features in item_styles.items())\n",
    ")\n",
    "print(interactions_matrix)\n",
    "# print(item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=30, loss='warp')\n",
    "model.fit(interactions_matrix, item_features=item_features, epochs=10, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, dataset, user_ids, n_items=5):\n",
    "    n_users, n_items_total = interactions_matrix.shape\n",
    "    item_ids = np.arange(n_items_total)\n",
    "    recommendations_per_user = {}\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        scores = model.predict(user_id, item_ids, item_features=item_features)\n",
    "        top_items = item_ids[np.argsort(-scores)][:n_items]\n",
    "        item_mapping = dataset.mapping()[2]\n",
    "        item_id_mapping = {v: k for k, v in item_mapping.items()}\n",
    "        recommended_items = [item_id_mapping[item] for item in top_items]\n",
    "        print(f\"User {user_id} recommended items: {recommended_items}\")\n",
    "        recommendations_per_user[user_id] = recommended_items\n",
    "    \n",
    "    return recommendations_per_user\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision = precision_at_k(model, interactions_matrix, item_features=item_features, k=5).mean()\n",
    "train_recall = recall_at_k(model, interactions_matrix, item_features=item_features, k=5).mean()\n",
    "\n",
    "print(f'Train precision at k: {train_precision}')\n",
    "print(f'Train Recall: {train_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_group = recommend(model, dataset, [1, 2, 3], n_items=1000)\n",
    "print(type(userslist))\n",
    "print(recommendations_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4vgMrNHWxWl"
   },
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
