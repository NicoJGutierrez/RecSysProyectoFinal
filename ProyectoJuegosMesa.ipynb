{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH8fyVEjke2x"
   },
   "source": [
    "# Propuesta Proyecto RecSys: Recomendación Grupal de Juegos de Mesa (setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygicq0KDTnqq"
   },
   "source": [
    "Link de dataset: https://www.kaggle.com/datasets/threnjen/board-games-database-from-boardgamegeek?select=games.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMyiOuV3TyEZ",
    "outputId": "c7b45953-faab-45cb-c214-110509412021"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!pip install pyreclab\n",
    "!pip install implicit\n",
    "!pip install surprise\n",
    "!pip install elliot\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzALElwIUwwS"
   },
   "source": [
    "Tutorial usado: https://www.kaggle.com/discussions/general/74235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu7OpwbIW4Hu"
   },
   "source": [
    "Tutorial adicional usado: https://www.youtube.com/watch?v=yEXkEUqK52Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8V2_lleq2w5",
    "outputId": "bc5cc37a-a6fd-454f-8565-5331a610e4ad"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"threnjen/board-games-database-from-boardgamegeek\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xKgz0X2q2w6"
   },
   "source": [
    "Arriba de esto aparecerá un \"path to dataset files\", ese path se debe copiar y pegar en la línea de abajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y1R8PyNW2pp"
   },
   "outputs": [],
   "source": [
    "path_to_dataset_files = path\n",
    "#path_to_dataset_files = '/home/nico/.cache/kagglehub/datasets/threnjen/board-games-database-from-boardgamegeek/versions/4'\n",
    "#path_to_dataset_files = '/root/.cache/kagglehub/datasets/threnjen/board-games-database-from-boardgamegeek/versions/4'\n",
    "\n",
    "import os\n",
    "# Guardamos el directorio actual\n",
    "base_dir = os.getcwd()\n",
    "# Cambiamos al directorio donde se encuentra el dataset\n",
    "os.chdir(path_to_dataset_files)\n",
    "\n",
    "# Importamos las librerias\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreclab\n",
    "import tempfile\n",
    "import implicit\n",
    "import random\n",
    "from surprise import accuracy\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZBjZKWDK2Uq"
   },
   "source": [
    "Generamos los datos a utilizar como un muestreo del dataset original pues es muy grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UX_VaAH9Xs-T",
    "outputId": "c7505886-1461-4785-b812-d0a970744e33"
   },
   "outputs": [],
   "source": [
    "# Leemos el csv y volvemos al directorio base del proyecto\n",
    "user_ratings = pd.read_csv('user_ratings.csv')\n",
    "mechanics_df = pd.read_csv('mechanics.csv')\n",
    "# Volvemos al directorio base del proyecto\n",
    "os.chdir(base_dir)\n",
    "print(base_dir)\n",
    "\n",
    "# Cambiamos username por un userid\n",
    "a=list(set(list(user_ratings.Username)))\n",
    "d = {a[i]: i for i in range(len(a))}\n",
    "a_mod = [d[i] for i in list(user_ratings.Username)]\n",
    "user_ratings[\"Username\"] = a_mod\n",
    "\n",
    "# Separamos training y testing\n",
    "train     = list(set(user_ratings.Username))[:8000]\n",
    "test      = list(set(user_ratings.Username))[8000:11000]\n",
    "test_set  = user_ratings[user_ratings[\"Username\"].isin(test)].sample(9000)\n",
    "train_set = user_ratings[user_ratings[\"Username\"].isin(train)].sample(35000)\n",
    "\n",
    "# Generamos nuevo csv de training y testing\n",
    "train_set.to_csv(\"train.csv\", index=False, sep=',', header=True)\n",
    "test_set.to_csv(\"test.csv\", index=False, sep=',', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vcXoaD-wYcB"
   },
   "source": [
    "# Creación de grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código importado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pni1vfFjwcCX"
   },
   "outputs": [],
   "source": [
    "# Groups generator from: https://github.com/barnap/group-recommenders-offline-evaluation/blob/main/synthetic_groups_generation/groups_generators.py\n",
    "\n",
    "class GroupsGenerator(ABC):\n",
    "\n",
    "    @staticmethod\n",
    "    def getGroupsGenerator(type):\n",
    "        if type == \"RANDOM\":\n",
    "            return RandomGroupsGenerator()\n",
    "        elif type == \"SIMILAR\":\n",
    "            return SimilarGroupsGenerator()\n",
    "        elif type == \"DIVERGENT\":\n",
    "            return DivergentGroupsGenerator()\n",
    "        elif type == \"SIMILAR_ONE_DIVERGENT\":\n",
    "            return MinorityGroupsGenerator()\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_average_similarity(group, user_id_indexes, sim_matrix):\n",
    "        similarities = list()\n",
    "        for user_1 in group:\n",
    "            user_1_index = user_id_indexes.tolist().index(user_1)\n",
    "            for user_2 in group:\n",
    "                user_2_index = user_id_indexes.tolist().index(user_2)\n",
    "                if user_1 != user_2:\n",
    "                    similarities.append(sim_matrix[user_1_index][user_2_index])\n",
    "        return np.mean(similarities)\n",
    "\n",
    "    @abstractmethod\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomGroupsGenerator(GroupsGenerator):\n",
    "\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            for i in range(group_number_to_create):\n",
    "                group = random.sample(user_id_set, group_size)\n",
    "                groups_list.append(\n",
    "                    {\n",
    "                        \"group_size\": group_size,\n",
    "                        \"group_similarity\": 'random',\n",
    "                        \"group_members\": group,\n",
    "                        \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                    }\n",
    "                )\n",
    "            print(len(groups_list))\n",
    "        return groups_list\n",
    "\n",
    "\n",
    "class SimilarGroupsGenerator(GroupsGenerator):\n",
    "\n",
    "    @staticmethod\n",
    "    def select_user_for_sim_group(group, sim_matrix, user_id_indexes, sim_threshold=0.4):\n",
    "        '''\n",
    "        Helper function to the generate_similar_user_groups function. Given already selected group members, it randomly\n",
    "        selects from the remaining users that has a PCC value >= sim_threshold to any of the existing members.\n",
    "        :param group:\n",
    "        :param sim_matrix:\n",
    "        :param user_id_indexes:\n",
    "        :param sim_threshold:\n",
    "        :return:\n",
    "        '''\n",
    "        ids_to_select_from = set()\n",
    "        for member in group:\n",
    "            member_index = user_id_indexes.tolist().index(member)\n",
    "            indexes = np.where(sim_matrix[member_index] >= sim_threshold)[0].tolist()\n",
    "            user_ids = [user_id_indexes[index] for index in indexes]\n",
    "            ids_to_select_from = ids_to_select_from.union(set(user_ids))\n",
    "        candidate_ids = ids_to_select_from.difference(set(group))\n",
    "        if len(candidate_ids) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            selection = random.sample(candidate_ids, 1)\n",
    "            return selection[0]\n",
    "\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            groups_size_list = list()\n",
    "            while (len(groups_size_list) < group_number_to_create):\n",
    "                group = random.sample(user_id_set, 1)\n",
    "                while len(group) < group_size:\n",
    "                    new_member = SimilarGroupsGenerator.select_user_for_sim_group(group, similarity_matrix,\n",
    "                                                                                  user_id_indexes,\n",
    "                                                                                  sim_threshold=0.5)\n",
    "                    if new_member is None:\n",
    "                        break\n",
    "                    group.append(new_member)\n",
    "                if len(group) == group_size:\n",
    "                    groups_size_list.append(\n",
    "                        {\n",
    "                            \"group_size\": group_size,\n",
    "                            \"group_similarity\": 'similar',\n",
    "                            \"group_members\": group,\n",
    "                            \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                        }\n",
    "                    )\n",
    "            groups_list.extend(groups_size_list)\n",
    "            print(len(groups_list))\n",
    "        return groups_list\n",
    "\n",
    "\n",
    "class DivergentGroupsGenerator(GroupsGenerator):\n",
    "\n",
    "    @staticmethod\n",
    "    def select_user_for_divergent_group(group, sim_matrix, user_id_indexes, sim_threshold=0.0):\n",
    "        '''\n",
    "        Helper function to the generate_similar_user_groups function. Given already selected group members, it randomly\n",
    "        selects from the remaining users that has a PCC value < sim_threshold to any of the existing members.\n",
    "        :param group:\n",
    "        :param sim_matrix:\n",
    "        :param user_id_indexes:\n",
    "        :param sim_threshold:\n",
    "        :return:\n",
    "        '''\n",
    "        ids_to_select_from = set()\n",
    "        for member in group:\n",
    "            member_index = user_id_indexes.tolist().index(member)\n",
    "            indexes = np.where(sim_matrix[member_index] < sim_threshold)[0].tolist()\n",
    "            user_ids = [user_id_indexes[index] for index in indexes]\n",
    "            ids_to_select_from = ids_to_select_from.union(set(user_ids))\n",
    "        candidate_ids = ids_to_select_from.difference(set(group))\n",
    "        if len(candidate_ids) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            selection = random.sample(candidate_ids, 1)\n",
    "            return selection[0]\n",
    "\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            groups_size_list = list()\n",
    "            while (len(groups_size_list) < group_number_to_create):\n",
    "                group = random.sample(user_id_set, 1)\n",
    "                while len(group) < group_size:\n",
    "                    new_member = DivergentGroupsGenerator.select_user_for_divergent_group(group, similarity_matrix,\n",
    "                                                                                     user_id_indexes,\n",
    "                                                                                     sim_threshold=-0.1)\n",
    "                    if new_member is None:\n",
    "                        break\n",
    "                    group.append(new_member)\n",
    "                if len(group) == group_size:\n",
    "                    groups_size_list.append(\n",
    "                        {\n",
    "                            \"group_size\": group_size,\n",
    "                            \"group_similarity\": 'divergent',\n",
    "                            \"group_members\": group,\n",
    "                            \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                        }\n",
    "                    )\n",
    "            groups_list.extend(groups_size_list)\n",
    "            print(len(groups_list))\n",
    "        return groups_list\n",
    "\n",
    "\n",
    "class MinorityGroupsGenerator(GroupsGenerator):\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            groups_size_list = list()\n",
    "            while (len(groups_size_list) < group_number_to_create):\n",
    "                group = random.sample(user_id_set, 1)\n",
    "                while len(group) < (group_size - 1):\n",
    "                    new_member = SimilarGroupsGenerator.select_user_for_sim_group(group, similarity_matrix,\n",
    "                                                                                     user_id_indexes,\n",
    "                                                                                     sim_threshold=0.5)\n",
    "                    if new_member is None:\n",
    "                        break\n",
    "                    group.append(new_member)\n",
    "\n",
    "                dissimilar_member = DivergentGroupsGenerator.select_user_for_divergent_group(group, similarity_matrix,\n",
    "                                                                                              user_id_indexes,\n",
    "                                                                                              sim_threshold=-0.1)\n",
    "                if dissimilar_member is not None:\n",
    "                    group.append(dissimilar_member)\n",
    "                if len(group) == group_size:\n",
    "                    groups_size_list.append(\n",
    "                        {\n",
    "                            \"group_size\": group_size,\n",
    "                            \"group_similarity\": 'similar_one_divergent',\n",
    "                            \"group_members\": group,\n",
    "                            \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                        }\n",
    "                    )\n",
    "            groups_list.extend(groups_size_list)\n",
    "            print(len(groups_list))\n",
    "        return groups_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código nuestro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh7Zuy7SN1QJ"
   },
   "source": [
    "Informacion para crear grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56xPcl69N0i6"
   },
   "outputs": [],
   "source": [
    "group_sizes_to_create = [4]        # [2, 3, 4, 5, 6, 7, 8]\n",
    "group_similarity_to_create = \"RANDOM\"  # [\"RANDOM\", \"SIMILAR\", \"DIVERGENT\", \"SIMILAR_ONE_DIVERGENT\"]\n",
    "group_number = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck2euynXwvOp"
   },
   "source": [
    "Creacion de los grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlVeyb3wwurd",
    "outputId": "8ee25c45-794d-4555-e1b3-1f28e2832941"
   },
   "outputs": [],
   "source": [
    "# Extraccion de un sample para poder manejarlo\n",
    "user_ratings = user_ratings.sample(5000)\n",
    "\n",
    "# Informacion del dataset\n",
    "user_matrix = user_ratings.pivot_table(columns='BGGId', index='Username', values='Rating')\n",
    "user_id_set = set(user_ratings['Username'])\n",
    "user_id_indexes = user_matrix.index.values\n",
    "user_matrix = user_matrix.fillna(0)\n",
    "numpy_array = user_matrix.to_numpy()\n",
    "sim_matrix = np.corrcoef(numpy_array)\n",
    "\n",
    "#Creacion del generador\n",
    "grpGenerator = GroupsGenerator.getGroupsGenerator(group_similarity_to_create)\n",
    "grpList = grpGenerator.generateGroups(user_id_indexes, user_id_set, sim_matrix, group_sizes_to_create, group_number)\n",
    "\n",
    "#display(pd.DataFrame.from_records(grpList))\n",
    "pd.DataFrame.from_records(grpList).to_csv('synthetic_groups.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhdLEKTqLXKj"
   },
   "source": [
    "# Evaluación de baselines para 1 usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "0g_ntaRqxwgK",
    "outputId": "315707fc-ae37-47a6-a865-16c8b100a0ab"
   },
   "outputs": [],
   "source": [
    "# Trabajaremos con un top 10\n",
    "top_n = 10\n",
    "test_set.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgqznCEGq2w7",
    "outputId": "7f56557f-f017-4ba3-a5a0-5650d16b4194"
   },
   "outputs": [],
   "source": [
    "# Revisemos el tamaño del dataset para asegurarnos de que tiene un tamaño trabajable:\n",
    "print(\"Tamaño del dataset completo:\", user_ratings.shape)\n",
    "print(\"Tamaño del dataset de entrenamiento:\", train_set.shape)\n",
    "print(\"Tamaño del dataset de prueba:\", test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "4rF526_4zGS7",
    "outputId": "d6a78f8b-b0d5-4a32-b15b-a4686f962a03"
   },
   "outputs": [],
   "source": [
    "# Evaluamos UserKNN\n",
    "myUserKnn = pyreclab.UserKnn(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myUserKnn.train(k=7, similarity='pearson')\n",
    "_, maeUK, rmseUK = myUserKnn.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapUK, ndcgUK = myUserKnn.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeUK} y rmse = {rmseUK}\")\n",
    "print(f\"map = {mapUK} y ndcg = {ndcgUK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUPkB3E4v1fo",
    "outputId": "69b494c9-67d0-4110-f8f1-2bca5084cbcb"
   },
   "outputs": [],
   "source": [
    "# Evaluamos ItemKNN\n",
    "myItemKnn = pyreclab.ItemKnn(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myItemKnn.train(k=7, similarity='pearson')\n",
    "_, maeIK, rmseIK = myItemKnn.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapIK, ndcgIK = myItemKnn.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeIK} y rmse = {rmseIK}\")\n",
    "print(f\"map = {mapIK} y ndcg = {ndcgIK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7L7aVu-qzRY_",
    "outputId": "023604bd-526e-44ef-e63a-533c21ae19e2"
   },
   "outputs": [],
   "source": [
    "# Evaluamos SVD\n",
    "mySVD = pyreclab.SVD(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "mySVD.train(factors=50, maxiter=80, lr=0.1, lamb=0.5)\n",
    "_, maeSVD, rmseSVD = mySVD.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapSVD, ndcgSVD = mySVD.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeSVD} y rmse = {rmseSVD}\")\n",
    "print(f\"map = {mapSVD} y ndcg = {ndcgSVD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efI8FJ00VMF2",
    "outputId": "0bebd840-5764-47ec-a765-ce0d53de9320"
   },
   "outputs": [],
   "source": [
    "# Evaluamos Most Popular\n",
    "myMP = pyreclab.MostPopular(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myMP.train(progress=False)\n",
    "_, mapMP, ndcgMP = myMP.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"map = {mapMP} y ndcg = {ndcgMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofL_ECIkRH-r",
    "outputId": "2a24baa8-e89d-4f97-8fef-bd99c59f2e8c"
   },
   "outputs": [],
   "source": [
    "# Evaluamos Random ratings\n",
    "predictions = []\n",
    "\n",
    "rating_scale = (1, 10)\n",
    "\n",
    "for _, row in test_set.iterrows():\n",
    "    itemId = row[\"BGGId\"]; rating = row[\"Rating\"]; userId = row[\"Username\"]\n",
    "    random_rating = random.uniform(rating_scale[0], rating_scale[1])\n",
    "    predictions.append((userId, itemId, rating, random_rating, None))\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zqp0_9BFq2w8"
   },
   "source": [
    "# Recomendación multimodal para un usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naFpdN49q2w8"
   },
   "source": [
    "Setup del metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiMiS3dwq2w8",
    "outputId": "09145191-786f-44f2-91d8-a89e7d215a42"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0TYGEdLq2w8"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = train_set\n",
    "cols_with_id = {col: idx for idx, col in enumerate(mechanics_df.columns[1:])}\n",
    "\n",
    "# Conjunto de features\n",
    "item_styles = {}\n",
    "\n",
    "for _, row in train_set.iterrows():\n",
    "    bgg_id = row['BGGId']\n",
    "    style_row = mechanics_df[mechanics_df['BGGId'] == bgg_id].drop(columns=['BGGId'])\n",
    "    styles = style_row.columns[style_row.iloc[0] == 1].tolist()\n",
    "    item_styles[bgg_id] = styles\n",
    "\n",
    "print(item_styles)\n",
    "\n",
    "\n",
    "\n",
    "itemslist = df['BGGId'].unique()\n",
    "userslist = df['Username'].unique()\n",
    "stylelist = [i for i in range(len(cols_with_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjunto de features, pero numericos\n",
    "\n",
    "item_styles_with_ids = {}\n",
    "for item_id, styles in item_styles.items():\n",
    "    style_ids = [cols_with_id[style] for style in styles]\n",
    "    item_styles_with_ids[item_id] = style_ids\n",
    "print(item_styles_with_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [(row['Username'], row['BGGId'], row['Rating']) for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "all_features = set(feature for features in item_styles.values() for feature in features)\n",
    "\n",
    "dataset.fit(users=userslist, items=itemslist, item_features=all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions_matrix, weights_matrix) = dataset.build_interactions(\n",
    "    ((x[0], x[1], x[2]) for x in interactions)\n",
    ")\n",
    "\n",
    "item_features = dataset.build_item_features(\n",
    "    ((item_id, features) for item_id, features in item_styles.items())\n",
    ")\n",
    "print(interactions_matrix)\n",
    "# print(item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=30, loss='warp')\n",
    "model.fit(interactions_matrix, item_features=item_features, epochs=10, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, dataset, user_ids, n_items=5):\n",
    "    n_users, n_items_total = interactions_matrix.shape\n",
    "    item_ids = np.arange(n_items_total)\n",
    "    recommendations_per_user = {}\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        scores = model.predict(user_id, item_ids, item_features=item_features)\n",
    "        top_items = item_ids[np.argsort(-scores)][:n_items]\n",
    "        item_mapping = dataset.mapping()[2]\n",
    "        item_id_mapping = {v: k for k, v in item_mapping.items()}\n",
    "        recommended_items = [item_id_mapping[item] for item in top_items]\n",
    "        print(f\"User {user_id} recommended items: {recommended_items}\")\n",
    "        recommendations_per_user[user_id] = recommended_items\n",
    "    \n",
    "    return recommendations_per_user\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision = precision_at_k(model, interactions_matrix, item_features=item_features, k=5).mean()\n",
    "train_recall = recall_at_k(model, interactions_matrix, item_features=item_features, k=5).mean()\n",
    "\n",
    "print(f'Train precision at k: {train_precision}')\n",
    "print(f'Train Recall: {train_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_group = recommend(model, dataset, [1, 2, 3], n_items=1000)\n",
    "print(type(userslist))\n",
    "print(recommendations_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4vgMrNHWxWl"
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ponderación para grupos de usuarios con recomendaciones de metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df = pd.read_csv('synthetic_groups.csv')\n",
    "groups_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código adaptado de repositorio mencionado anteriormente, en este caso tomamos los items que en promedio son más preferidos para recomendarlos al grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_group(model, dataset, group_members, n_items=5):\n",
    "    n_users, n_items_total = interactions_matrix.shape\n",
    "    item_ids = np.arange(n_items_total)\n",
    "    user_mapping = dataset.mapping()[0]\n",
    "    \n",
    "    group_scores = []\n",
    "    for user_id in group_members:\n",
    "        try:\n",
    "            internal_user_id = user_mapping[user_id]\n",
    "            scores = model.predict(internal_user_id, item_ids, item_features=item_features)\n",
    "            group_scores.append(scores)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    if not group_scores:\n",
    "        return []\n",
    "    \n",
    "    average_scores = np.mean(group_scores, axis=0)\n",
    "    top_items = item_ids[np.argsort(-average_scores)][:n_items]\n",
    "    \n",
    "    item_mapping = dataset.mapping()[2]\n",
    "    item_id_mapping = {v: k for k, v in item_mapping.items()}\n",
    "    recommended_items = [item_id_mapping[item] for item in top_items]\n",
    "    \n",
    "    return recommended_items\n",
    "\n",
    "group_recommendations = []\n",
    "for _, row in groups_df.iterrows():\n",
    "    group_members = eval(row['group_members']) if isinstance(row['group_members'], str) else row['group_members']\n",
    "    recommendations = recommend_for_group(model, dataset, group_members, n_items=10)\n",
    "    group_recommendations.append({\n",
    "        'group_members': group_members,\n",
    "        'recommendations': recommendations\n",
    "    })\n",
    "\n",
    "recommendations_df = pd.DataFrame(group_recommendations)\n",
    "recommendations_df.to_csv('group_recommendations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
