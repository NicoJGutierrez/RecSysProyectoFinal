{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH8fyVEjke2x"
   },
   "source": [
    "# Propuesta Proyecto RecSys: Recomendación Grupal de Juegos de Mesa (setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygicq0KDTnqq"
   },
   "source": [
    "Link de dataset: https://www.kaggle.com/datasets/threnjen/board-games-database-from-boardgamegeek?select=games.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMyiOuV3TyEZ",
    "outputId": "c7b45953-faab-45cb-c214-110509412021"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!pip install pyreclab\n",
    "!pip install implicit\n",
    "!pip install surprise\n",
    "!pip install elliot\n",
    "!pip install torch torchvision\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzALElwIUwwS"
   },
   "source": [
    "Tutorial usado: https://www.kaggle.com/discussions/general/74235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu7OpwbIW4Hu"
   },
   "source": [
    "Tutorial adicional usado: https://www.youtube.com/watch?v=yEXkEUqK52Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8V2_lleq2w5",
    "outputId": "bc5cc37a-a6fd-454f-8565-5331a610e4ad"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"threnjen/board-games-database-from-boardgamegeek\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xKgz0X2q2w6"
   },
   "source": [
    "Arriba de esto aparecerá un \"path to dataset files\", ese path se debe copiar y pegar en la línea de abajo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y1R8PyNW2pp"
   },
   "outputs": [],
   "source": [
    "#path_to_dataset_files = '/home/nico/.cache/kagglehub/datasets/threnjen/board-games-database-from-boardgamegeek/versions/4'\n",
    "path_to_dataset_files = '/root/.cache/kagglehub/datasets/threnjen/board-games-database-from-boardgamegeek/versions/4'\n",
    "\n",
    "import os\n",
    "# Guardamos el directorio actual\n",
    "base_dir = os.getcwd()\n",
    "# Cambiamos al directorio donde se encuentra el dataset\n",
    "os.chdir(path_to_dataset_files)\n",
    "\n",
    "# Importamos las librerias\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreclab\n",
    "import tempfile\n",
    "import implicit\n",
    "import random\n",
    "from surprise import accuracy\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZBjZKWDK2Uq"
   },
   "source": [
    "Generamos los datos a utilizar como un muestreo del dataset original pues es muy grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UX_VaAH9Xs-T",
    "outputId": "c7505886-1461-4785-b812-d0a970744e33"
   },
   "outputs": [],
   "source": [
    "# Leemos el csv y volvemos al directorio base del proyecto\n",
    "user_ratings = pd.read_csv('user_ratings.csv')\n",
    "# Volvemos al directorio base del proyecto\n",
    "os.chdir(base_dir)\n",
    "print(base_dir)\n",
    "\n",
    "# Cambiamos username por un userid\n",
    "a=list(set(list(user_ratings.Username)))\n",
    "d = {a[i]: i for i in range(len(a))}\n",
    "a_mod = [d[i] for i in list(user_ratings.Username)]\n",
    "user_ratings[\"Username\"] = a_mod\n",
    "\n",
    "# Separamos training y testing\n",
    "train     = list(set(user_ratings.Username))[:8000]\n",
    "test      = list(set(user_ratings.Username))[8000:11000]\n",
    "test_set  = user_ratings[user_ratings[\"Username\"].isin(test)].sample(9000)\n",
    "train_set = user_ratings[user_ratings[\"Username\"].isin(train)].sample(35000)\n",
    "\n",
    "# Generamos nuevo csv de training y testing\n",
    "train_set.to_csv(\"train.csv\", index=False, sep=',', header=True)\n",
    "test_set.to_csv(\"test.csv\", index=False, sep=',', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vcXoaD-wYcB"
   },
   "source": [
    "# Creación de grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pni1vfFjwcCX"
   },
   "outputs": [],
   "source": [
    "# Groups generator from: https://github.com/barnap/group-recommenders-offline-evaluation/blob/main/synthetic_groups_generation/groups_generators.py\n",
    "\n",
    "class GroupsGenerator(ABC):\n",
    "\n",
    "    @staticmethod\n",
    "    def getGroupsGenerator(type):\n",
    "        if type == \"RANDOM\":\n",
    "            return RandomGroupsGenerator()\n",
    "        elif type == \"SIMILAR\":\n",
    "            return SimilarGroupsGenerator()\n",
    "        elif type == \"DIVERGENT\":\n",
    "            return DivergentGroupsGenerator()\n",
    "        elif type == \"SIMILAR_ONE_DIVERGENT\":\n",
    "            return MinorityGroupsGenerator()\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_average_similarity(group, user_id_indexes, sim_matrix):\n",
    "        similarities = list()\n",
    "        for user_1 in group:\n",
    "            user_1_index = user_id_indexes.tolist().index(user_1)\n",
    "            for user_2 in group:\n",
    "                user_2_index = user_id_indexes.tolist().index(user_2)\n",
    "                if user_1 != user_2:\n",
    "                    similarities.append(sim_matrix[user_1_index][user_2_index])\n",
    "        return np.mean(similarities)\n",
    "\n",
    "    @abstractmethod\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomGroupsGenerator(GroupsGenerator):\n",
    "\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            for i in range(group_number_to_create):\n",
    "                group = random.sample(user_id_set, group_size)\n",
    "                groups_list.append(\n",
    "                    {\n",
    "                        \"group_size\": group_size,\n",
    "                        \"group_similarity\": 'random',\n",
    "                        \"group_members\": group,\n",
    "                        \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                    }\n",
    "                )\n",
    "            print(len(groups_list))\n",
    "        return groups_list\n",
    "\n",
    "\n",
    "class SimilarGroupsGenerator(GroupsGenerator):\n",
    "\n",
    "    @staticmethod\n",
    "    def select_user_for_sim_group(group, sim_matrix, user_id_indexes, sim_threshold=0.4):\n",
    "        '''\n",
    "        Helper function to the generate_similar_user_groups function. Given already selected group members, it randomly\n",
    "        selects from the remaining users that has a PCC value >= sim_threshold to any of the existing members.\n",
    "        :param group:\n",
    "        :param sim_matrix:\n",
    "        :param user_id_indexes:\n",
    "        :param sim_threshold:\n",
    "        :return:\n",
    "        '''\n",
    "        ids_to_select_from = set()\n",
    "        for member in group:\n",
    "            member_index = user_id_indexes.tolist().index(member)\n",
    "            indexes = np.where(sim_matrix[member_index] >= sim_threshold)[0].tolist()\n",
    "            user_ids = [user_id_indexes[index] for index in indexes]\n",
    "            ids_to_select_from = ids_to_select_from.union(set(user_ids))\n",
    "        candidate_ids = ids_to_select_from.difference(set(group))\n",
    "        if len(candidate_ids) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            selection = random.sample(candidate_ids, 1)\n",
    "            return selection[0]\n",
    "\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            groups_size_list = list()\n",
    "            while (len(groups_size_list) < group_number_to_create):\n",
    "                group = random.sample(user_id_set, 1)\n",
    "                while len(group) < group_size:\n",
    "                    new_member = SimilarGroupsGenerator.select_user_for_sim_group(group, similarity_matrix,\n",
    "                                                                                  user_id_indexes,\n",
    "                                                                                  sim_threshold=0.5)\n",
    "                    if new_member is None:\n",
    "                        break\n",
    "                    group.append(new_member)\n",
    "                if len(group) == group_size:\n",
    "                    groups_size_list.append(\n",
    "                        {\n",
    "                            \"group_size\": group_size,\n",
    "                            \"group_similarity\": 'similar',\n",
    "                            \"group_members\": group,\n",
    "                            \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                        }\n",
    "                    )\n",
    "            groups_list.extend(groups_size_list)\n",
    "            print(len(groups_list))\n",
    "        return groups_list\n",
    "\n",
    "\n",
    "class DivergentGroupsGenerator(GroupsGenerator):\n",
    "\n",
    "    @staticmethod\n",
    "    def select_user_for_divergent_group(group, sim_matrix, user_id_indexes, sim_threshold=0.0):\n",
    "        '''\n",
    "        Helper function to the generate_similar_user_groups function. Given already selected group members, it randomly\n",
    "        selects from the remaining users that has a PCC value < sim_threshold to any of the existing members.\n",
    "        :param group:\n",
    "        :param sim_matrix:\n",
    "        :param user_id_indexes:\n",
    "        :param sim_threshold:\n",
    "        :return:\n",
    "        '''\n",
    "        ids_to_select_from = set()\n",
    "        for member in group:\n",
    "            member_index = user_id_indexes.tolist().index(member)\n",
    "            indexes = np.where(sim_matrix[member_index] < sim_threshold)[0].tolist()\n",
    "            user_ids = [user_id_indexes[index] for index in indexes]\n",
    "            ids_to_select_from = ids_to_select_from.union(set(user_ids))\n",
    "        candidate_ids = ids_to_select_from.difference(set(group))\n",
    "        if len(candidate_ids) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            selection = random.sample(candidate_ids, 1)\n",
    "            return selection[0]\n",
    "\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            groups_size_list = list()\n",
    "            while (len(groups_size_list) < group_number_to_create):\n",
    "                group = random.sample(user_id_set, 1)\n",
    "                while len(group) < group_size:\n",
    "                    new_member = DivergentGroupsGenerator.select_user_for_divergent_group(group, similarity_matrix,\n",
    "                                                                                     user_id_indexes,\n",
    "                                                                                     sim_threshold=-0.1)\n",
    "                    if new_member is None:\n",
    "                        break\n",
    "                    group.append(new_member)\n",
    "                if len(group) == group_size:\n",
    "                    groups_size_list.append(\n",
    "                        {\n",
    "                            \"group_size\": group_size,\n",
    "                            \"group_similarity\": 'divergent',\n",
    "                            \"group_members\": group,\n",
    "                            \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                        }\n",
    "                    )\n",
    "            groups_list.extend(groups_size_list)\n",
    "            print(len(groups_list))\n",
    "        return groups_list\n",
    "\n",
    "\n",
    "class MinorityGroupsGenerator(GroupsGenerator):\n",
    "    def generateGroups(self, user_id_indexes, user_id_set, similarity_matrix, group_sizes_to_create, group_number_to_create):\n",
    "        groups_list = list()\n",
    "        for group_size in group_sizes_to_create:\n",
    "            groups_size_list = list()\n",
    "            while (len(groups_size_list) < group_number_to_create):\n",
    "                group = random.sample(user_id_set, 1)\n",
    "                while len(group) < (group_size - 1):\n",
    "                    new_member = SimilarGroupsGenerator.select_user_for_sim_group(group, similarity_matrix,\n",
    "                                                                                     user_id_indexes,\n",
    "                                                                                     sim_threshold=0.5)\n",
    "                    if new_member is None:\n",
    "                        break\n",
    "                    group.append(new_member)\n",
    "\n",
    "                dissimilar_member = DivergentGroupsGenerator.select_user_for_divergent_group(group, similarity_matrix,\n",
    "                                                                                              user_id_indexes,\n",
    "                                                                                              sim_threshold=-0.1)\n",
    "                if dissimilar_member is not None:\n",
    "                    group.append(dissimilar_member)\n",
    "                if len(group) == group_size:\n",
    "                    groups_size_list.append(\n",
    "                        {\n",
    "                            \"group_size\": group_size,\n",
    "                            \"group_similarity\": 'similar_one_divergent',\n",
    "                            \"group_members\": group,\n",
    "                            \"avg_similarity\": GroupsGenerator.compute_average_similarity(group, user_id_indexes, similarity_matrix)\n",
    "                        }\n",
    "                    )\n",
    "            groups_list.extend(groups_size_list)\n",
    "            print(len(groups_list))\n",
    "        return groups_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh7Zuy7SN1QJ"
   },
   "source": [
    "Informacion para crear grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56xPcl69N0i6"
   },
   "outputs": [],
   "source": [
    "group_sizes_to_create = [4]        # [2, 3, 4, 5, 6, 7, 8]\n",
    "group_similarity_to_create = \"RANDOM\"  # [\"RANDOM\", \"SIMILAR\", \"DIVERGENT\", \"SIMILAR_ONE_DIVERGENT\"]\n",
    "group_number = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck2euynXwvOp"
   },
   "source": [
    "Creacion de los grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlVeyb3wwurd",
    "outputId": "8ee25c45-794d-4555-e1b3-1f28e2832941"
   },
   "outputs": [],
   "source": [
    "# Extraccion de un sample para poder manejarlo\n",
    "user_ratings = user_ratings.sample(5000)\n",
    "\n",
    "# Informacion del dataset\n",
    "user_matrix = user_ratings.pivot_table(columns='BGGId', index='Username', values='Rating')\n",
    "user_id_set = set(user_ratings['Username'])\n",
    "user_id_indexes = user_matrix.index.values\n",
    "user_matrix = user_matrix.fillna(0)\n",
    "numpy_array = user_matrix.to_numpy()\n",
    "sim_matrix = np.corrcoef(numpy_array)\n",
    "\n",
    "#Creacion del generador\n",
    "grpGenerator = GroupsGenerator.getGroupsGenerator(group_similarity_to_create)\n",
    "grpList = grpGenerator.generateGroups(user_id_indexes, user_id_set, sim_matrix, group_sizes_to_create, group_number)\n",
    "\n",
    "#display(pd.DataFrame.from_records(grpList))\n",
    "pd.DataFrame.from_records(grpList).to_csv('synthetic_groups.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhdLEKTqLXKj"
   },
   "source": [
    "# Evaluación de baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "0g_ntaRqxwgK",
    "outputId": "315707fc-ae37-47a6-a865-16c8b100a0ab"
   },
   "outputs": [],
   "source": [
    "# Trabajaremos con un top 10\n",
    "top_n = 10\n",
    "test_set.head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgqznCEGq2w7",
    "outputId": "7f56557f-f017-4ba3-a5a0-5650d16b4194"
   },
   "outputs": [],
   "source": [
    "# Revisemos el tamaño del dataset para asegurarnos de que tiene un tamaño trabajable:\n",
    "print(\"Tamaño del dataset completo:\", user_ratings.shape)\n",
    "print(\"Tamaño del dataset de entrenamiento:\", train_set.shape)\n",
    "print(\"Tamaño del dataset de prueba:\", test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "4rF526_4zGS7",
    "outputId": "d6a78f8b-b0d5-4a32-b15b-a4686f962a03"
   },
   "outputs": [],
   "source": [
    "# Evaluamos UserKNN\n",
    "myUserKnn = pyreclab.UserKnn(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myUserKnn.train(k=7, similarity='pearson')\n",
    "_, maeUK, rmseUK = myUserKnn.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapUK, ndcgUK = myUserKnn.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeUK} y rmse = {rmseUK}\")\n",
    "print(f\"map = {mapUK} y ndcg = {ndcgUK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUPkB3E4v1fo",
    "outputId": "69b494c9-67d0-4110-f8f1-2bca5084cbcb"
   },
   "outputs": [],
   "source": [
    "# Evaluamos ItemKNN\n",
    "myItemKnn = pyreclab.ItemKnn(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myItemKnn.train(k=7, similarity='pearson')\n",
    "_, maeIK, rmseIK = myItemKnn.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapIK, ndcgIK = myItemKnn.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeIK} y rmse = {rmseIK}\")\n",
    "print(f\"map = {mapIK} y ndcg = {ndcgIK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7L7aVu-qzRY_",
    "outputId": "023604bd-526e-44ef-e63a-533c21ae19e2"
   },
   "outputs": [],
   "source": [
    "# Evaluamos SVD\n",
    "mySVD = pyreclab.SVD(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "mySVD.train(factors=50, maxiter=80, lr=0.1, lamb=0.5)\n",
    "_, maeSVD, rmseSVD = mySVD.test(input_file = 'test.csv', dlmchar = b',', header = False, usercol = 2, itemcol = 0, ratingcol = 1)\n",
    "_, mapSVD, ndcgSVD = mySVD.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"mae = {maeSVD} y rmse = {rmseSVD}\")\n",
    "print(f\"map = {mapSVD} y ndcg = {ndcgSVD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efI8FJ00VMF2",
    "outputId": "0bebd840-5764-47ec-a765-ce0d53de9320"
   },
   "outputs": [],
   "source": [
    "# Evaluamos Most Popular\n",
    "myMP = pyreclab.MostPopular(dataset='train.csv', dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1)\n",
    "myMP.train(progress=False)\n",
    "_, mapMP, ndcgMP = myMP.testrec(input_file=\"test.csv\", dlmchar=b',', header=False, usercol=2, itemcol=0, ratingcol=1, topn=top_n)\n",
    "\n",
    "print(f\"map = {mapMP} y ndcg = {ndcgMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofL_ECIkRH-r",
    "outputId": "2a24baa8-e89d-4f97-8fef-bd99c59f2e8c"
   },
   "outputs": [],
   "source": [
    "# Evaluamos Random ratings\n",
    "predictions = []\n",
    "\n",
    "rating_scale = (1, 10)\n",
    "\n",
    "for _, row in test_set.iterrows():\n",
    "    itemId = row[\"BGGId\"]; rating = row[\"Rating\"]; userId = row[\"Username\"]\n",
    "    random_rating = random.uniform(rating_scale[0], rating_scale[1])\n",
    "    predictions.append((userId, itemId, rating, random_rating, None))\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zqp0_9BFq2w8"
   },
   "source": [
    "# Recomendación multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naFpdN49q2w8"
   },
   "source": [
    "Setup de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmUB5ACZq2w8",
    "outputId": "418f1f5b-400e-438c-b8ca-11694ee2aba6"
   },
   "outputs": [],
   "source": [
    "os.chdir(path_to_dataset_files)\n",
    "juegos = pd.read_csv('games.csv')\n",
    "os.chdir(base_dir)\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df['BGGId'] = train_df['BGGId'].astype(int)\n",
    "test_df['BGGId'] = test_df['BGGId'].astype(int)\n",
    "juegos['BGGId'] = juegos['BGGId'].astype(int)\n",
    "\n",
    "train_pictures = pd.merge(train_df, juegos[['BGGId', 'ImagePath']], on='BGGId', how='left')\n",
    "test_pictures = pd.merge(test_df, juegos[['BGGId', 'ImagePath']], on='BGGId', how='left')\n",
    "\n",
    "\n",
    "train_pictures_dict = train_pictures.set_index('BGGId')['ImagePath'].to_dict()\n",
    "test_pictures_dict = test_pictures.set_index('BGGId')['ImagePath'].to_dict()\n",
    "\n",
    "print(train_pictures_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiMiS3dwq2w8",
    "outputId": "09145191-786f-44f2-91d8-a89e7d215a42"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0TYGEdLq2w8"
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet.eval()\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4vgMrNHWxWl"
   },
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
